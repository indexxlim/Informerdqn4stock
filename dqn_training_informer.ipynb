{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f539d429-902f-4f85-966f-8553dd6ba1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from data_preprocessing import Data\n",
    "from trading_env import TradingEnv, RunAgent\n",
    "from agent import Agent, Informer_Agent\n",
    "from model import DQN\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def training(args):\n",
    "    T = args.T\n",
    "    M = args.bs # minibatch size\n",
    "    alpha = args.lr # Learning rate\n",
    "    gamma = args.gamma # Discount factor\n",
    "    theta = args.para_target # Target network\n",
    "    n_units = args.n_units # number of units in a hidden layer\n",
    "    closing_path = os.path.join(args.root_path, 'data_closing/' + args.stock + '-closing.json')\n",
    "    states_path = os.path.join(args.root_path, 'data_states/' + args.stock + '-states.json')\n",
    "\n",
    "    RunAgent(TradingEnv(Data(closing_path, states_path, T)), Agent()).run(5000, args)\n",
    "\n",
    "    # weight initialization!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321f976-7197-4d74-9717-c7d254db7de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b280359f-a09c-43af-ab3b-3ce376333b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='DQN_Trading')\n",
    "parser.add_argument('--root_path', type=str, default='./', help=\"root path\")\n",
    "parser.add_argument('--gpu_id', type=str, default='0', help=\"device id to run\")\n",
    "parser.add_argument('--agent', type=float, default=0.001, help=\"the parameter which controls the soft update\")\n",
    "parser.add_argument('--bs', type=int, default=16, help=\"training batch size\")\n",
    "parser.add_argument('--lr', type=float, default=0.00025, help=\"training learning rate\")\n",
    "parser.add_argument('--gamma', type=float, default=0.001, help=\"the discount factor of Q learning\")\n",
    "parser.add_argument('--n_units', type=int, default=32, help=\"the number of units in a hidden layer\")\n",
    "parser.add_argument('--T', type=int, default=84, help=\"the length of series data\")\n",
    "parser.add_argument('--stock', type=str, default='AIG', help=\"determine which stock\")\n",
    "parser.add_argument('--seed', type=int, default=2037, help=\"random seed\")\n",
    "parser.add_argument('--para_target', type=float, default=0.001, help=\"the parameter which controls the soft update\")\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "SEED = args.seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "file_path = './data_closing/'\n",
    "datafile_list = os.listdir(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcaa1ec-f4e3-4709-b1e0-356ead7273d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.stock = \"KRW-ADA_20210320_20220324_84\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07a1f2-0b7c-4262-b895-3e2d81d31e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56c619-b216-4ad0-a408-43b94a8beb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRW-ADA_20210320_20220324_84\n",
      "4367100.0\n"
     ]
    }
   ],
   "source": [
    "print(args.stock)\n",
    "SEED = args.seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b91580c-8eb1-4ce3-b20b-e58d49f9e6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRW-ADA_20210320_20220324_84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/.local/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6706600.0\n",
      "5961050.0\n",
      "7418050.0\n",
      "10237350.0\n",
      "10410650.0\n"
     ]
    }
   ],
   "source": [
    "print(args.stock)\n",
    "SEED = args.seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5bbcbc-a86f-442e-803d-e99dd57aec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = args.T\n",
    "M = args.bs # minibatch size\n",
    "alpha = args.lr # Learning rate\n",
    "gamma = args.gamma # Discount factor\n",
    "theta = args.para_target # Target network\n",
    "n_units = args.n_units # number of units in a hidden layer\n",
    "closing_path = os.path.join(args.root_path, 'data_closing/' + args.stock + '-closing.json')\n",
    "states_path = os.path.join(args.root_path, 'data_states/' + args.stock + '-states.json')\n",
    "\n",
    "\n",
    "# weight initialization!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35af7488-a194-4980-a2a9-b6e835a74276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(closing_path, states_path, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d6c416-d2ea-4da3-9c00-26b5ad6a2043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_states/KRW-ADA_20210320_20220324_84-states.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closing_path\n",
    "states_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3b0ea9-31f1-4511-8312-74a391a6b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RunAgent(TradingEnv(Data(closing_path, states_path, T)), Agent()).run(5000, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5038c934-7260-4ae6-a69f-7e21dfc47027",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5000\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb6966-fb69-4790-a655-03203397ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/.local/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6056450.0\n",
      "-4488300.0\n"
     ]
    }
   ],
   "source": [
    "agent =RunAgent(TradingEnv(Data(closing_path, states_path, T)), Informer_Agent()).run(5000, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7e554a6-7880-4659-98f4-a75b6883f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.env.reset() # initial_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dab52d9-54a8-45bb-8dc9-f2a4981a54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08c67a7c-49f6-4f75-9dee-de49cbfb77dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "action = agent.agent.act(state) # select greedy action, exploration is done in step-method\n",
    "actions, rewards, new_states, state, done = agent.env.step(action, step)\n",
    "\n",
    "agent.agent.store(state, actions, new_states, rewards, action, step)\n",
    "print(len(agent.agent.memory))\n",
    "agent.agent.optimize(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7464627e-3710-4267-82de-466fbdfce1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import Transition, ReplayMemory\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e4ce432-b371-4e6b-acf6-6c4f41cd4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = agent.agent.memory.sample(agent.agent.batch_size)\n",
    "# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "# detailed explanation). This converts batch-array of Transitions\n",
    "# to Transition of batch-arrays.\n",
    "batch = Transition(*zip(*transitions))\n",
    "\n",
    "# Compute a mask of non-final states and concatenate the batch elements\n",
    "# (a final state would've been the one after which simulation ended)\n",
    "next_state = torch.FloatTensor(batch.next_state).to(device)\n",
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, next_state)))\n",
    "non_final_next_states = torch.cat([s for s in next_state if s is not None])\n",
    "\n",
    "state_batch = torch.FloatTensor(batch.state).to(device)\n",
    "action_batch = torch.LongTensor(torch.add(torch.tensor(batch.action), torch.tensor(1))).to(device)\n",
    "reward_batch = torch.FloatTensor(batch.reward).to(device)\n",
    "\n",
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "# chane model lstm to informer\n",
    "#l = self.policy_net(state_batch).size(0)\n",
    "batch_x, batch_x_mark, batch_y, batch_y_mark = agent.agent.informer_input(state_batch)\n",
    "state_action_values = agent.agent.policy_net(batch_x, batch_x_mark, batch_y, batch_y_mark).squeeze().max(1)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(agent.agent.batch_size, device=device)\n",
    "batch_x, batch_x_mark, batch_y, batch_y_mark = agent.agent.informer_input(next_state)\n",
    "next_state_values[non_final_mask] = agent.agent.target_net(batch_x, batch_x_mark, batch_y, batch_y_mark).squeeze().max(1)[0]\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * agent.agent.gamma) + reward_batch\n",
    "\n",
    "# Compute the loss\n",
    "loss = torch.nn.MSELoss()(expected_state_action_values, state_action_values)\n",
    "\n",
    "# Optimize the model\n",
    "\n",
    "loss.backward()\n",
    "#for param in agent.agent.policy_net.parameters():\n",
    "#        param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "agent.agent.optimizer.step()\n",
    "\n",
    "if step % agent.agent.T == 0:\n",
    "    # print('soft_update')\n",
    "    gamma = 0.001\n",
    "    param_before = copy.deepcopy(agent.agent.target_net)\n",
    "    target_update = copy.deepcopy(agent.agent.target_net.state_dict())\n",
    "    for k in target_update.keys():\n",
    "        target_update[k] = agent.agent.target_net.state_dict()[k] * (1 - gamma) + agent.agent.policy_net.state_dict()[k] * gamma\n",
    "    agent.agent.target_net.load_state_dict(target_update)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab06c587-1d14-4f02-8553-99a3fa8769de",
   "metadata": {},
   "outputs": [],
   "source": [
    "param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e171c2b-7f8d-48b8-ba48-6c3366f3dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65011d-cbe8-4186-a477-2f19549ff508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b1cf6b5-d953-4542-8ad8-c09274314bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ebc533513452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minformer_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/study/informer/DRQN_Stock_Trading/code_server/agent.py\u001b[0m in \u001b[0;36minformer_input\u001b[0;34m(self, state_batch)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mbatch_y_mark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mdec_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mdec_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_x\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_x\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "agent.agent.informer_input(next_state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd834082-6a8f-43ec-8e47-abbe379bc073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(agent.agent.batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80714faa-072a-4bde-b973-912da9915566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f58263c8-246e-4a5c-9e6d-aee985dd9b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a5f432f-cdff-4578-ba2f-17b5d2a73b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d8f7f9c-f701-40c8-9e29-5941de8181bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5298f620-f0c2-4c07-a240-3a69d2ac2b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if len(agent.agent.memory) < agent.agent.batch_size * 10:\n",
    "#     return\n",
    "transitions = agent.agent.memory.sample(agent.agent.batch_size)\n",
    "# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "# detailed explanation). This converts batch-array of Transitions\n",
    "# to Transition of batch-arrays.\n",
    "batch = Transition(*zip(*transitions))\n",
    "\n",
    "# Compute a mask of non-final states and concatenate the batch elements\n",
    "# (a final state would've been the one after which simulation ended)\n",
    "next_state = torch.FloatTensor(batch.next_state).to(device)\n",
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, next_state)))\n",
    "non_final_next_states = torch.cat([s for s in next_state if s is not None])\n",
    "\n",
    "state_batch = torch.FloatTensor(batch.state).to(device)\n",
    "action_batch = torch.LongTensor(torch.add(torch.tensor(batch.action), torch.tensor(1))).to(device)\n",
    "reward_batch = torch.FloatTensor(batch.reward).to(device)\n",
    "\n",
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "l = agent.agent.policy_net(state_batch).size(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "state_action_values = agent.agent.policy_net(state_batch)[agent.agent.T-1:l:agent.agent.T].gather(1, action_batch.reshape((agent.agent.batch_size, 1)))\n",
    "state_action_values = state_action_values.squeeze(-1)\n",
    "\n",
    "\n",
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(agent.agent.batch_size, device=device)\n",
    "next_state_values[non_final_mask] = agent.agent.target_net(next_state)[agent.agent.T-1:l:agent.agent.T].max(1)[0].detach()\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * agent.agent.gamma) + reward_batch\n",
    "\n",
    "# Compute the loss\n",
    "loss = torch.nn.MSELoss()(expected_state_action_values, state_action_values)\n",
    "\n",
    "# Optimize the model\n",
    "\n",
    "loss.backward()\n",
    "for param in agent.agent.policy_net.parameters():\n",
    "    param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "agent.agent.optimizer.step()\n",
    "\n",
    "if step % agent.agent.T == 0:\n",
    "    print('soft_update')\n",
    "gamma = 0.001\n",
    "param_before = copy.deepcopy(agent.agent.target_net)\n",
    "target_update = copy.deepcopy(agent.agent.target_net.state_dict())\n",
    "for k in target_update.keys():\n",
    "    target_update[k] = agent.agent.target_net.state_dict()[k] * (1 - gamma) + agent.agent.policy_net.state_dict()[k] * gamma\n",
    "agent.agent.target_net.load_state_dict(target_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d098f2a0-52c4-4e47-b851-d81f98ec356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_action_values = agent.agent.policy_net(state_batch)[agent.agent.T-1:l:agent.agent.T].gather(1, action_batch.reshape((agent.agent.batch_size, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dd3cd65-3397-49c5-a9c7-80b9dfa28ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8befe950-4d4f-4e48-8e88-69832eba6efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1752,  8.1532, 14.1446, -4.7372,  9.9657,  1.6826, -0.0201, 10.3614,\n",
       "        15.9313, -4.4890, -9.1605,  1.9446, -1.1246,  0.4593,  3.1795,  1.4774],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecffb9d-289a-4451-b30b-74e0a26263a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed499dbb-7896-4ba3-87d4-be5ec2351449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1589,  0.0453,  0.0434, -0.0080,  0.0396,  0.0083, -0.0106,  0.0420,\n",
       "         0.1315,  0.0087,  0.1765,  0.1443,  0.1407,  0.1642,  0.0020,  0.0470],\n",
       "       device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.target_net(next_state)[agent.agent.T-1:l:agent.agent.T].max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a2f662-6cc0-4a92-a273-021e0c2c8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import Informer\n",
    "\n",
    "label_len=84\n",
    "pred_len = 3\n",
    "model = Informer(1, 1, 1, 84, 84, 3, device = device).to(device)\n",
    "\n",
    "def informer_input(state_batch):\n",
    "    batch_x = state_batch.float().to(device)\n",
    "    batch_y = state_batch.float()\n",
    "    batch_x_mark = state_batch.float().to(device)\n",
    "    batch_y_mark = state_batch.float().to(device)\n",
    "    dec_inp = torch.zeros([state_batch.shape[0], pred_len, state_batch.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([state_batch[:,:label_len,:], state_batch], dim=1).float().to(device)\n",
    "    batch_x[batch_x < 0] = 0\n",
    "    batch_x[batch_x > 5] = 0\n",
    "    return batch_x[:16,:,:1], batch_x_mark[:16,:,:5], dec_inp[:16,:84,:1], batch_y_mark[:16,:84,:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84dc3db5-8760-4b2f-b9ed-bef15569df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/.local/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_x_mark, batch_y, batch_y_mark = informer_input(state_batch)\n",
    "state_action_values = model(batch_x, batch_x_mark, batch_y, batch_y_mark).squeeze().max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d6c81e3-1935-4713-80a2-10fc18578555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state_values = torch.zeros(agent.agent.batch_size, device=device)\n",
    "next_state_values[non_final_mask] = agent.agent.target_net(next_state)[agent.agent.T-1:l:agent.agent.T].max(1)[0].detach()\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * agent.agent.gamma) + reward_batch\n",
    "\n",
    "# Compute the loss\n",
    "loss = torch.nn.MSELoss()(expected_state_action_values, state_action_values)\n",
    "\n",
    "# Optimize the model\n",
    "\n",
    "loss.backward()\n",
    "for param in agent.agent.policy_net.parameters():\n",
    "    param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "agent.agent.optimizer.step()\n",
    "\n",
    "if step % agent.agent.T == 0:\n",
    "    print('soft_update')\n",
    "gamma = 0.001\n",
    "param_before = copy.deepcopy(agent.agent.target_net)\n",
    "target_update = copy.deepcopy(agent.agent.target_net.state_dict())\n",
    "for k in target_update.keys():\n",
    "    target_update[k] = agent.agent.target_net.state_dict()[k] * (1 - gamma) + agent.agent.policy_net.state_dict()[k] * gamma\n",
    "agent.agent.target_net.load_state_dict(target_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5cd2a80-0ebf-44b2-8b3c-b3f8bb184850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30caf661-e811-4beb-8806-09a6030fea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_x_mark, batch_y, batch_y_mark = informer_input(next_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee4a56ff-9524-4a6e-8b11-ed6691189ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_action_values = model(batch_x, batch_x_mark, batch_y, batch_y_mark).squeeze().max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d65ab344-ed83-4964-9b99-c8fd164876a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249b88a-65e7-456a-80ba-83652ed4ffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "584bff50-2d52-4530-aec9-73c291823399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1589,  0.0453,  0.0434, -0.0080,  0.0396,  0.0083, -0.0106,  0.0420,\n",
       "         0.1315,  0.0087,  0.1765,  0.1443,  0.1407,  0.1642,  0.0020,  0.0470],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state_values[non_final_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f5c0155-1e83-4a38-b5b6-71eeac7aa404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb48b49-0f9e-412e-93a4-c0e3bbd19ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f969d-c11c-4da3-8ef3-a094536b3c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29304d-ad91-403e-a07d-3c797b622dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63fd52e4-efe1-4313-9eec-d5fb520e6560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (first_two_layers): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       "  (lstm): LSTM(256, 256, batch_first=True)\n",
       "  (last_linear): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb758bef-cc49-446e-aa56-64ecc3281e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "032dcaa7-8f74-4f2c-a64a-cedd73987444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4809,  3.1719, -2.6508],\n",
       "        [10.3841,  1.4601, -1.2563],\n",
       "        [10.7359,  0.8411, -3.1959],\n",
       "        ...,\n",
       "        [ 1.5511, 10.1949, -8.1049],\n",
       "        [ 2.0535,  4.0915,  1.2815],\n",
       "        [-1.7908,  8.5168,  3.0911]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.policy_net(state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fa7a324-581d-46db-a872-335929c60adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 84, 14])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3eb6147-dfa5-4a88-89a6-8f7ffeb5e313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (first_two_layers): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       "  (lstm): LSTM(256, 256, batch_first=True)\n",
       "  (last_linear): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa7cd0-490a-4d91-8597-acb43e71a333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3582197d-9609-4fcb-891a-3f8364d0a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4bdeaf7aea4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select greedy action, exploration is done in step-method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/study/informer/DRQN_Stock_Trading/code_server/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "state = agent.env.reset() # initial_state\n",
    "\n",
    "for step in range(episodes):\n",
    "    action = agent.agent.act(state) # select greedy action, exploration is done in step-method\n",
    "\n",
    "    actions, rewards, new_states, state, done = agent.env.step(action, step)\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    agent.agent.store(state, actions, new_states, rewards, action, step)\n",
    "    agent.agent.optimize(step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4194b93-b0f0-45cd-bfda-cec21a3c8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.env.print_stats(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de928e-f895-4bfe-8ad8-e4a56e09c539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4425e025-97bb-4c0d-ad37-19dadbd4be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('batch.pickle', 'rb') as handle:\n",
    "    batch = pickle.load(handle)\n",
    "state_batch = torch.FloatTensor(batch.state).to(device)\n",
    "\n",
    "batch_x = state_batch.float().to(device)\n",
    "batch_y = state_batch.float()\n",
    "batch_x_mark = state_batch.float().to(device)\n",
    "batch_y_mark = state_batch.float().to(device)\n",
    "dec_inp = torch.zeros([state_batch.shape[0], pred_len, state_batch.shape[-1]]).float()\n",
    "dec_inp = torch.cat([state_batch[:,:label_len,:], state_batch], dim=1).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74dee015-397c-49a0-8ee5-423903372408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import Informer\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18847a30-ff89-4313-b5b2-593a44d9e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "model = Informer(1, 1, 1, 84, 84, 3, device = device).to(device)\n",
    "pred_len=84\n",
    "label_len=84\n",
    "\n",
    "#with open('batch.pickle', 'wb') as handle:\n",
    "#    pickle.dump(batch, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('batch.pickle', 'rb') as handle:\n",
    "    batch = pickle.load(handle)\n",
    "\n",
    "state_batch = torch.FloatTensor(batch.state).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f83faa5-3c3f-464d-826f-97fdf5705a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as weight_init\n",
    "\n",
    "for param_p in model.parameters(): \n",
    "    weight_init.normal_(param_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "378a2c9e-8bd0-483f-bf07-406f60d361fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = state_batch.float().to(device)\n",
    "batch_y = state_batch.float()\n",
    "batch_x_mark = state_batch.float().to(device)\n",
    "batch_y_mark = state_batch.float().to(device)\n",
    "dec_inp = torch.zeros([state_batch.shape[0], pred_len, state_batch.shape[-1]]).float()\n",
    "dec_inp = torch.cat([state_batch[:,:label_len,:], state_batch], dim=1).float().to(device)\n",
    "batch_x[batch_x < 0] = 0\n",
    "batch_x[batch_x > 5] = 0\n",
    "\n",
    "outputs = model(batch_x[:10,:,:1], batch_x_mark[:10,:,:5], dec_inp[:10,:84,:1], batch_y_mark[:10,:84,:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6737173-0443-4c07-a556-85b1a70ba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb16e3-c123-4718-84fd-1dae4e7e4833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a46fdcb5-2d88-44a7-9c8a-c950795f6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3154, 1.0376, 0.3154, 0.6597, 1.0058, 1.0376, 0.8619, 1.1936, 0.9132,\n",
       "        0.8046], device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.squeeze().max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2005e450-65f4-4184-a6b4-3ec2e8f1d7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c01c50-dd7c-4ca5-a041-b3e963f84666",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y = batch_y[:,-pred_len:,0:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c3a85-fa7d-4a59-bf0a-f0edffd224b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5c3eb8f1-1f82-4501-a6f7-e6ff2cecf92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 1, 3], expected input[16, 14, 98] to have 1 channels, but got 14 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-ac688d9eb87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/study/informer/DRQN_Stock_Trading/code_server/models/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m     68\u001b[0m     def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n\u001b[1;32m     69\u001b[0m                 enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mark_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_self_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/study/informer/DRQN_Stock_Trading/code_server/models/embed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_mark)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/study/informer/DRQN_Stock_Trading/code_server/models/embed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[0m\u001b[1;32m    292\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                             _single(0), self.dilation, self.groups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 1, 3], expected input[16, 14, 98] to have 1 channels, but got 14 channels instead"
     ]
    }
   ],
   "source": [
    "model(state_batch,state_batch,state_batch,state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f4b5f-bf6f-410c-812c-3ff5943b9dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab7764-c887-401f-87a5-523b2cd808bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
